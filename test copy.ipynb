{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gibbsibp import UncollapsedGibbsIBP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cp_pres_1</th>\n",
       "      <th>cp_pres_2</th>\n",
       "      <th>cp_pres_3</th>\n",
       "      <th>cp_pres_4</th>\n",
       "      <th>cp_pres_5</th>\n",
       "      <th>cp_pres_6</th>\n",
       "      <th>cp_pres_7</th>\n",
       "      <th>cp_pres_8</th>\n",
       "      <th>cp_pres_9</th>\n",
       "      <th>cp_pres_10</th>\n",
       "      <th>...</th>\n",
       "      <th>cp_pres_14</th>\n",
       "      <th>cp_pres_15</th>\n",
       "      <th>cp_pres_16</th>\n",
       "      <th>cp_pres_17</th>\n",
       "      <th>cp_pres_18</th>\n",
       "      <th>cp_pres_19</th>\n",
       "      <th>cp_pres_20</th>\n",
       "      <th>cp_pres_21</th>\n",
       "      <th>cp_pres_22</th>\n",
       "      <th>cp_pres_23</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   cp_pres_1  cp_pres_2  cp_pres_3  cp_pres_4  cp_pres_5  cp_pres_6  \\\n",
       "0          0          0          0          0          0          0   \n",
       "1          0          0          0          0          0          0   \n",
       "2          0          0          0          0          0          0   \n",
       "3          0          0          0          0          0          0   \n",
       "4          0          0          0          0          0          0   \n",
       "\n",
       "   cp_pres_7  cp_pres_8  cp_pres_9  cp_pres_10  ...  cp_pres_14  cp_pres_15  \\\n",
       "0          0          0          0           0  ...           0           0   \n",
       "1          0          0          0           0  ...           0           0   \n",
       "2          0          0          0           0  ...           0           0   \n",
       "3          0          0          0           0  ...           0           0   \n",
       "4          0          0          0           0  ...           0           0   \n",
       "\n",
       "   cp_pres_16  cp_pres_17  cp_pres_18  cp_pres_19  cp_pres_20  cp_pres_21  \\\n",
       "0           0           0           0           0           0           0   \n",
       "1           0           0           0           0           0           0   \n",
       "2           0           0           0           0           0           0   \n",
       "3           0           0           0           0           0           0   \n",
       "4           0           0           0           0           0           0   \n",
       "\n",
       "   cp_pres_22  cp_pres_23  \n",
       "0           0           0  \n",
       "1           0           0  \n",
       "2           0           0  \n",
       "3           0           0  \n",
       "4           0           0  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_excel('training_data.xlsx')\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "conditions = []\n",
    "                                                                                                # COMMUNICATION FROM SABYA:\n",
    "conditions.append({'force':np.array([ 0., 0.]),             'cue':np.array([0., 0., 0., 0.,])}) # 0: is null/ control you can ignore\n",
    "conditions.append({'force':np.array([-0.866025404, 0.5]),   'cue':np.array([1., 0., 0., 0.,])}) # 1,2: elements\n",
    "conditions.append({'force':np.array([ 0.866025404, 0.5]),   'cue':np.array([0., 0., 1., 0.,])})\n",
    "conditions.append({'force':np.array([ 0.,-1.]),             'cue':np.array([0., 1., 0., 0.,])}) # 3: not visual and not dynamic compositional\n",
    "conditions.append({'force':np.array([ 0.866025404, -0.5]),  'cue':np.array([0., 0., 0., 1.,])}) # 4: not visual but dynamic compositional\n",
    "conditions.append({'force':np.array([ 0, 1]),               'cue':np.array([1., 0., 1., 0.,])}) # 5: visual and dynamic compositional\n",
    "conditions.append({'force':np.array([-0.866025404, -0.5]),  'cue':np.array([0., 1., 1., 0.,])}) # 6: not dynamic but visual compositional\n",
    "\n",
    "for condition in conditions:\n",
    "    condition['force'] = condition['force']/4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_input_data(condition_seq):\n",
    "    \"\"\"\n",
    "    Generate input data for the model, based on sequences of conditions experienced by the subjects.\n",
    "    \"\"\"\n",
    "    X_dataset = []\n",
    "    F_dataset = []\n",
    "\n",
    "    for condition in condition_seq:\n",
    "        X_dataset.append(conditions[condition]['cue'])\n",
    "        F_dataset.append(conditions[condition]['force'])\n",
    "\n",
    "    X_dataset = torch.tensor(X_dataset, dtype=torch.float32)\n",
    "    F_dataset = torch.tensor(F_dataset, dtype=torch.float32)\n",
    "\n",
    "    return X_dataset, F_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "630\n"
     ]
    }
   ],
   "source": [
    "seq_1 = dataset['cp_pres_1'].to_list()\n",
    "seq_1 = [int(x) for x in seq_1]\n",
    "seq_1 = [x for x in seq_1 if x != 0]\n",
    "print(len(seq_1))\n",
    "seq_1 = seq_1[:200]\n",
    "\n",
    "X_dataset, F_dataset = generate_input_data(seq_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def add_noise_to_obs(X, F, F_noise_std = 0.01, lambd=0.98, epsilon=0.02):\n",
    "#     \"\"\"\n",
    "#     Add gaussian noise to force data, and randomly flip pixels in the observation data\n",
    "#     \"\"\"\n",
    "#     F += torch.randn(F.size()) * F_noise_std\n",
    "    \n",
    "#     X_noisy = torch.zeros(X.size())\n",
    "#     for i in range(X.size()[0]):\n",
    "#         for j in range(X.size()[1]):\n",
    "#             if X[i, j] == 1:\n",
    "#                 X_noisy[i, j] = 1 if random() < lambd else 0\n",
    "#             else:\n",
    "#                 X_noisy[i, j] = 1 if random() < epsilon else 0\n",
    "\n",
    "#     return X_noisy, F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 1., 1., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [0., 0., 0., 1.],\n",
      "        [0., 0., 1., 0.],\n",
      "        [0., 1., 0., 0.]])\n",
      "tensor([[-0.2165, -0.1250],\n",
      "        [-0.2165,  0.1250],\n",
      "        [ 0.2165, -0.1250],\n",
      "        [ 0.2165,  0.1250],\n",
      "        [ 0.0000, -0.2500]])\n"
     ]
    }
   ],
   "source": [
    "# X_dataset, F_dataset = add_noise_to_obs(X_dataset, F_dataset)\n",
    "\n",
    "print(X_dataset[:5,])\n",
    "print(F_dataset[:5,])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cProfile\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         1353593 function calls in 4.820 seconds\n",
      "\n",
      "   Ordered by: cumulative time\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "        1    0.000    0.000    4.820    4.820 gibbsibp.py:534(gibbs)\n",
      "        5    0.022    0.004    4.788    0.958 gibbsibp.py:380(resample_Z)\n",
      "     1000    0.335    0.000    4.311    0.004 gibbsibp.py:330(sample_k_new)\n",
      "    10000    0.750    0.000    1.587    0.000 gibbsibp.py:245(F_loglik_given_k_new)\n",
      "    10000    0.524    0.000    1.450    0.000 gibbsibp.py:291(X_loglik_given_k_new)\n",
      "    10000    0.114    0.000    0.593    0.000 poisson.py:66(log_prob)\n",
      "   129325    0.079    0.000    0.569    0.000 _tensor.py:34(wrapped)\n",
      "     1000    0.062    0.000    0.456    0.000 gibbsibp.py:177(resample_Z_ik)\n",
      "    83245    0.035    0.000    0.347    0.000 _tensor.py:907(__rsub__)\n",
      "    83245    0.312    0.000    0.312    0.000 {built-in method torch.rsub}\n",
      "     9010    0.311    0.000    0.311    0.000 {method 'inverse' of 'torch._C._TensorBase' objects}\n",
      "    10000    0.283    0.000    0.283    0.000 gibbsibp.py:317(<listcomp>)\n",
      "    10000    0.072    0.000    0.253    0.000 distribution.py:270(_validate_sample)\n",
      "     9000    0.010    0.000    0.214    0.000 <__array_function__ internals>:177(slogdet)\n",
      "     9004    0.008    0.000    0.202    0.000 {built-in method numpy.core._multiarray_umath.implement_array_function}\n",
      "     9000    0.114    0.000    0.195    0.000 linalg.py:1998(slogdet)\n",
      "    64096    0.172    0.000    0.172    0.000 {method 'pow' of 'torch._C._TensorBase' objects}\n",
      "    12224    0.021    0.000    0.155    0.000 utils.py:22(broadcast_all)\n",
      "     2000    0.034    0.000    0.143    0.000 gibbsibp.py:143(X_loglik_given_ZY)\n",
      "     2000    0.089    0.000    0.139    0.000 gibbsibp.py:99(F_loglik_given_ZA)\n",
      "    10000    0.134    0.000    0.134    0.000 constraints.py:317(check)\n",
      "    22200    0.129    0.000    0.129    0.000 {built-in method torch.tensor}\n",
      "     3235    0.023    0.000    0.102    0.000 distribution.py:38(__init__)\n",
      "    12224    0.038    0.000    0.093    0.000 functional.py:44(broadcast_tensors)\n",
      "    10000    0.084    0.000    0.084    0.000 {built-in method torch.cat}\n",
      "    12051    0.073    0.000    0.073    0.000 {built-in method torch.matmul}\n",
      "    22040    0.068    0.000    0.068    0.000 {built-in method torch.sum}\n",
      "     1000    0.007    0.000    0.061    0.000 categorical.py:51(__init__)\n",
      "    25110    0.061    0.000    0.061    0.000 {built-in method torch.log}\n",
      "    10000    0.055    0.000    0.055    0.000 {method 'xlogy' of 'torch._C._TensorBase' objects}\n",
      "     1024    0.004    0.000    0.052    0.000 bernoulli.py:42(__init__)\n",
      "    23019    0.051    0.000    0.051    0.000 {built-in method torch.zeros}\n",
      "    21005    0.047    0.000    0.047    0.000 {method 'transpose' of 'torch._C._TensorBase' objects}\n",
      "     1000    0.007    0.000    0.047    0.000 categorical.py:128(sample)\n",
      "    13301    0.045    0.000    0.045    0.000 {method 'all' of 'torch._C._TensorBase' objects}\n",
      "    12224    0.044    0.000    0.044    0.000 {built-in method torch.broadcast_tensors}\n",
      "    24448    0.014    0.000    0.041    0.000 {built-in method builtins.all}\n",
      "    10000    0.039    0.000    0.039    0.000 {method 'lgamma' of 'torch._C._TensorBase' objects}\n",
      "    15000    0.037    0.000    0.037    0.000 {method 'log' of 'torch._C._TensorBase' objects}\n",
      "     9000    0.036    0.000    0.036    0.000 {built-in method torch.ones}\n",
      "     9016    0.036    0.000    0.036    0.000 {method 'numpy' of 'torch._C._TensorBase' objects}\n",
      "     9006    0.035    0.000    0.035    0.000 {built-in method torch.eye}\n",
      "     1200    0.003    0.000    0.035    0.000 poisson.py:45(__init__)\n",
      "    18000    0.033    0.000    0.033    0.000 {method 'astype' of 'numpy.generic' objects}\n",
      "     1000    0.032    0.000    0.032    0.000 {built-in method torch.multinomial}\n",
      "     1000    0.022    0.000    0.032    0.000 constraints.py:439(check)\n",
      "     9000    0.017    0.000    0.028    0.000 linalg.py:136(_commonType)\n",
      "     1024    0.005    0.000    0.026    0.000 bernoulli.py:102(sample)\n",
      "    11000    0.022    0.000    0.022    0.000 {built-in method torch.trace}\n",
      "     1020    0.011    0.000    0.022    0.000 gibbsibp.py:235(renormalize_log_prob_pair)\n",
      "        1    0.008    0.008    0.021    0.021 gibbsibp.py:65(init_Z)\n",
      "   141549    0.020    0.000    0.020    0.000 {built-in method torch._C._has_torch_function}\n",
      "    51256    0.018    0.000    0.018    0.000 {method 'size' of 'torch._C._TensorBase' objects}\n",
      "    34448    0.010    0.000    0.017    0.000 utils.py:38(<genexpr>)\n",
      "     1024    0.017    0.000    0.017    0.000 constraints.py:399(check)\n",
      "     1000    0.007    0.000    0.016    0.000 gibbsibp.py:230(renormalize_log_probs)\n",
      "     4205    0.013    0.000    0.013    0.000 {method 'sum' of 'torch._C._TensorBase' objects}\n",
      "     2000    0.008    0.000    0.012    0.000 _tensor.py:911(__rdiv__)\n",
      "    34448    0.007    0.000    0.010    0.000 utils.py:43(<genexpr>)\n",
      "    44448    0.010    0.000    0.010    0.000 overrides.py:1776(is_tensor_like)\n",
      "    17518    0.005    0.000    0.010    0.000 {built-in method builtins.getattr}\n",
      "    12224    0.006    0.000    0.009    0.000 _VF.py:26(__getattr__)\n",
      "    18000    0.006    0.000    0.009    0.000 linalg.py:130(_realType)\n",
      "     1200    0.008    0.000    0.008    0.000 constraints.py:362(check)\n",
      "    22895    0.005    0.000    0.007    0.000 {built-in method builtins.isinstance}\n",
      "     9000    0.007    0.000    0.007    0.000 linalg.py:186(_assert_stacked_square)\n",
      "    18000    0.005    0.000    0.007    0.000 linalg.py:117(isComplexType)\n",
      "        5    0.002    0.000    0.006    0.001 gibbsibp.py:482(resample_Y)\n",
      "    10000    0.006    0.000    0.006    0.000 gibbsibp.py:318(<listcomp>)\n",
      "     1024    0.006    0.000    0.006    0.000 {built-in method torch.bernoulli}\n",
      "     4080    0.006    0.000    0.006    0.000 {built-in method torch.exp}\n",
      "     9000    0.005    0.000    0.005    0.000 linalg.py:180(_assert_stacked_2d)\n",
      "     2011    0.005    0.000    0.005    0.000 {method 'reshape' of 'torch._C._TensorBase' objects}\n",
      "     2235    0.005    0.000    0.005    0.000 distribution.py:256(_extended_shape)\n",
      "     2046    0.002    0.000    0.005    0.000 utils.py:122(__get__)\n",
      "     1000    0.004    0.000    0.004    0.000 {built-in method torch.all}\n",
      "     2000    0.004    0.000    0.004    0.000 {method 'reciprocal' of 'torch._C._TensorBase' objects}\n",
      "     1235    0.002    0.000    0.004    0.000 grad_mode.py:78(__enter__)\n",
      "     1246    0.004    0.000    0.004    0.000 {method 'expand' of 'torch._C._TensorBase' objects}\n",
      "     1000    0.004    0.000    0.004    0.000 {method 'abs' of 'torch._C._TensorBase' objects}\n",
      "     1020    0.004    0.000    0.004    0.000 {built-in method torch.max}\n",
      "        5    0.001    0.000    0.004    0.001 gibbsibp.py:429(resample_A)\n",
      "     2470    0.002    0.000    0.003    0.000 grad_mode.py:182(__init__)\n",
      "      200    0.001    0.000    0.003    0.000 poisson.py:61(sample)\n",
      "    27000    0.003    0.000    0.003    0.000 {built-in method builtins.issubclass}\n",
      "     5292    0.002    0.000    0.003    0.000 constraints.py:147(is_dependent)\n",
      "     1000    0.003    0.000    0.003    0.000 {method 'exp' of 'torch._C._TensorBase' objects}\n",
      "    20054    0.003    0.000    0.003    0.000 {built-in method builtins.len}\n",
      "     2046    0.003    0.000    0.003    0.000 utils.py:138(__init__)\n",
      "    18000    0.003    0.000    0.003    0.000 {method 'get' of 'dict' objects}\n",
      "     1000    0.003    0.000    0.003    0.000 {method 'max' of 'torch._C._TensorBase' objects}\n",
      "     1235    0.002    0.000    0.002    0.000 grad_mode.py:73(__init__)\n",
      "     1235    0.001    0.000    0.002    0.000 grad_mode.py:82(__exit__)\n",
      "     2224    0.001    0.000    0.002    0.000 <frozen abc>:117(__instancecheck__)\n",
      "     9000    0.002    0.000    0.002    0.000 {built-in method numpy.asarray}\n",
      "       11    0.000    0.000    0.002    0.000 multivariate_normal.py:129(__init__)\n",
      "     9000    0.001    0.000    0.001    0.000 linalg.py:465(_unary_dispatcher)\n",
      "     2224    0.001    0.000    0.001    0.000 {built-in method _abc._abc_instancecheck}\n",
      "     1235    0.001    0.000    0.001    0.000 _contextlib.py:149(__new__)\n",
      "     2470    0.001    0.000    0.001    0.000 {built-in method torch._C._set_grad_enabled}\n",
      "       11    0.000    0.000    0.001    0.000 constraints.py:553(check)\n",
      "      200    0.001    0.000    0.001    0.000 {built-in method torch.rand}\n",
      "       11    0.000    0.000    0.001    0.000 constraints.py:529(check)\n",
      "      200    0.001    0.000    0.001    0.000 {built-in method torch.poisson}\n",
      "     3705    0.001    0.000    0.001    0.000 {built-in method torch.is_grad_enabled}\n",
      "       11    0.000    0.000    0.001    0.000 distribution.py:158(sample)\n",
      "        1    0.000    0.000    0.001    0.001 gibbsibp.py:56(left_order_form)\n",
      "        1    0.000    0.000    0.001    0.001 gibbsibp.py:30(init_A)\n",
      "     3235    0.000    0.000    0.000    0.000 {method 'items' of 'dict' objects}\n",
      "       11    0.000    0.000    0.000    0.000 {built-in method torch.isclose}\n",
      "       11    0.000    0.000    0.000    0.000 multivariate_normal.py:239(rsample)\n",
      "        1    0.000    0.000    0.000    0.000 numeric.py:150(ones)\n",
      "        5    0.000    0.000    0.000    0.000 {built-in method builtins.print}\n",
      "     1235    0.000    0.000    0.000    0.000 {built-in method __new__ of type object at 0x860f60}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method numpy.empty}\n",
      "       10    0.000    0.000    0.000    0.000 iostream.py:610(write)\n",
      "        1    0.000    0.000    0.000    0.000 gibbsibp.py:43(init_Y)\n",
      "     1000    0.000    0.000    0.000    0.000 {method 'numel' of 'torch.Size' objects}\n",
      "       10    0.000    0.000    0.000    0.000 iostream.py:532(_schedule_flush)\n",
      "     1044    0.000    0.000    0.000    0.000 {method 'dim' of 'torch._C._TensorBase' objects}\n",
      "        5    0.000    0.000    0.000    0.000 iostream.py:243(schedule)\n",
      "        5    0.000    0.000    0.000    0.000 gibbsibp.py:90(remove_allzeros_ZAY)\n",
      "       11    0.000    0.000    0.000    0.000 constraints.py:219(check)\n",
      "     1246    0.000    0.000    0.000    0.000 _jit_internal.py:1109(is_scripting)\n",
      "       11    0.000    0.000    0.000    0.000 multivariate_normal.py:11(_batch_mv)\n",
      "      201    0.000    0.000    0.000    0.000 {method 'item' of 'torch._C._TensorBase' objects}\n",
      "       11    0.000    0.000    0.000    0.000 functional.py:76(broadcast_shapes)\n",
      "     1000    0.000    0.000    0.000    0.000 {method 'ndimension' of 'torch._C._TensorBase' objects}\n",
      "       11    0.000    0.000    0.000    0.000 utils.py:56(_standard_normal)\n",
      "        5    0.000    0.000    0.000    0.000 socket.py:543(send)\n",
      "       11    0.000    0.000    0.000    0.000 {built-in method torch._C._linalg.linalg_cholesky_ex}\n",
      "       11    0.000    0.000    0.000    0.000 constraints.py:515(check)\n",
      "       11    0.000    0.000    0.000    0.000 {built-in method torch._C._linalg.linalg_cholesky}\n",
      "       11    0.000    0.000    0.000    0.000 {method 'eq' of 'torch._C._TensorBase' objects}\n",
      "       11    0.000    0.000    0.000    0.000 {built-in method torch.full}\n",
      "       11    0.000    0.000    0.000    0.000 {method 'normal_' of 'torch._C._TensorBase' objects}\n",
      "       11    0.000    0.000    0.000    0.000 constraints.py:331(check)\n",
      "       16    0.000    0.000    0.000    0.000 {method 'clone' of 'torch._C._TensorBase' objects}\n",
      "       11    0.000    0.000    0.000    0.000 _trace.py:1110(is_tracing)\n",
      "       11    0.000    0.000    0.000    0.000 {built-in method torch.empty}\n",
      "        5    0.000    0.000    0.000    0.000 threading.py:1185(is_alive)\n",
      "       11    0.000    0.000    0.000    0.000 {method 'squeeze' of 'torch._C._TensorBase' objects}\n",
      "       11    0.000    0.000    0.000    0.000 {method 'unsqueeze' of 'torch._C._TensorBase' objects}\n",
      "        1    0.000    0.000    0.000    0.000 <__array_function__ internals>:177(cumprod)\n",
      "       10    0.000    0.000    0.000    0.000 iostream.py:505(_is_master_process)\n",
      "        1    0.000    0.000    0.000    0.000 <__array_function__ internals>:177(copyto)\n",
      "       11    0.000    0.000    0.000    0.000 {built-in method torch._C._is_tracing}\n",
      "        2    0.000    0.000    0.000    0.000 fromnumeric.py:51(_wrapfunc)\n",
      "        1    0.000    0.000    0.000    0.000 fromnumeric.py:3084(cumprod)\n",
      "        1    0.000    0.000    0.000    0.000 <__array_function__ internals>:177(dot)\n",
      "       11    0.000    0.000    0.000    0.000 {built-in method torch._C._get_tracing_state}\n",
      "        5    0.000    0.000    0.000    0.000 threading.py:1118(_wait_for_tstate_lock)\n",
      "        5    0.000    0.000    0.000    0.000 iostream.py:127(_event_pipe)\n",
      "        1    0.000    0.000    0.000    0.000 <__array_function__ internals>:177(take)\n",
      "        1    0.000    0.000    0.000    0.000 {method 'cumprod' of 'numpy.ndarray' objects}\n",
      "       10    0.000    0.000    0.000    0.000 {built-in method posix.getpid}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method torch.from_numpy}\n",
      "        5    0.000    0.000    0.000    0.000 {method 'acquire' of '_thread.lock' objects}\n",
      "        1    0.000    0.000    0.000    0.000 fromnumeric.py:93(take)\n",
      "        5    0.000    0.000    0.000    0.000 threading.py:568(is_set)\n",
      "        1    0.000    0.000    0.000    0.000 cProfile.py:118(__exit__)\n",
      "       10    0.000    0.000    0.000    0.000 {method 'write' of '_io.StringIO' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'take' of 'numpy.ndarray' objects}\n",
      "       10    0.000    0.000    0.000    0.000 {method '__exit__' of '_thread.RLock' objects}\n",
      "       15    0.000    0.000    0.000    0.000 {method 'append' of 'list' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'argsort' of 'numpy.ndarray' objects}\n",
      "        5    0.000    0.000    0.000    0.000 {method 'append' of 'collections.deque' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\n",
      "        1    0.000    0.000    0.000    0.000 multiarray.py:1079(copyto)\n",
      "        1    0.000    0.000    0.000    0.000 fromnumeric.py:3080(_cumprod_dispatcher)\n",
      "        1    0.000    0.000    0.000    0.000 multiarray.py:740(dot)\n",
      "        1    0.000    0.000    0.000    0.000 fromnumeric.py:89(_take_dispatcher)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "inf = UncollapsedGibbsIBP(alpha=0.05, K=1, max_K=4, sigma_a=0.2, sigma_n=0.1, epsilon=0.05, lambd=0.99, phi=0.25)\n",
    "with cProfile.Profile() as pr:\n",
    "    As, Zs, Ys = inf.gibbs(F_dataset, X_dataset, 5)\n",
    "\n",
    "pr.print_stats(sort='cumtime')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 0/100\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[60], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m inf \u001b[38;5;241m=\u001b[39m UncollapsedGibbsIBP(alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.05\u001b[39m, K\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, max_K\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m6\u001b[39m, sigma_a\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, sigma_n\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.01\u001b[39m, epsilon\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.01\u001b[39m, lambd\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.99\u001b[39m, phi\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.25\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m As, Zs, Ys \u001b[38;5;241m=\u001b[39m inf\u001b[38;5;241m.\u001b[39mgibbs(F_dataset, X_dataset, \u001b[38;5;241m100\u001b[39m)\n",
      "File \u001b[0;32m~/Cloud/Projects/_Contextual_Inference/IBP_method/gibbsibp.py:555\u001b[0m, in \u001b[0;36mUncollapsedGibbsIBP.gibbs\u001b[0;34m(self, F, X, iters)\u001b[0m\n\u001b[1;32m    553\u001b[0m A       \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresample_A(F,Z)\n\u001b[1;32m    554\u001b[0m Y       \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresample_Y(Z,X,Y)\n\u001b[0;32m--> 555\u001b[0m Z, A, Y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresample_Z(Z,F,X,A,Y)\n\u001b[1;32m    557\u001b[0m \u001b[38;5;66;03m# cleanup\u001b[39;00m\n\u001b[1;32m    558\u001b[0m Z, A, Y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mremove_allzeros_ZAY(Z,A,Y)\n",
      "File \u001b[0;32m~/Cloud/Projects/_Contextual_Inference/IBP_method/gibbsibp.py:404\u001b[0m, in \u001b[0;36mUncollapsedGibbsIBP.resample_Z\u001b[0;34m(self, Z, F, X, A, Y)\u001b[0m\n\u001b[1;32m    401\u001b[0m     Z[i,k] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresample_Z_ik(Z,F,X,A,Y,i,k)\n\u001b[1;32m    403\u001b[0m \u001b[38;5;66;03m# Decide how many new features to draw\u001b[39;00m\n\u001b[0;32m--> 404\u001b[0m k_new \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msample_k_new(Z,F,X,A,Y,i)\n\u001b[1;32m    406\u001b[0m \u001b[38;5;66;03m# Limit such that current_k + k_new <= max_K\u001b[39;00m\n\u001b[1;32m    407\u001b[0m \u001b[38;5;66;03m# current_k = A.size()[0]\u001b[39;00m\n\u001b[1;32m    408\u001b[0m \u001b[38;5;66;03m# k_new = np.clip(k_new, 0, self.max_K - current_k)\u001b[39;00m\n\u001b[1;32m    409\u001b[0m \n\u001b[1;32m    410\u001b[0m \u001b[38;5;66;03m# If new features are drawn, add them to Z, A, and Y\u001b[39;00m\n\u001b[1;32m    411\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m k_new \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    412\u001b[0m     \u001b[38;5;66;03m# Add new columns to Z\u001b[39;00m\n",
      "File \u001b[0;32m~/Cloud/Projects/_Contextual_Inference/IBP_method/gibbsibp.py:357\u001b[0m, in \u001b[0;36mUncollapsedGibbsIBP.sample_k_new\u001b[0;34m(self, Z, F, X, A, Y, i, truncation)\u001b[0m\n\u001b[1;32m    353\u001b[0m X_log_likelihood \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(truncation)\n\u001b[1;32m    355\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(truncation):\n\u001b[1;32m    356\u001b[0m     \u001b[38;5;66;03m# Compute the prior probability of k_new equaling j\u001b[39;00m\n\u001b[0;32m--> 357\u001b[0m     prior_poisson_probs[j] \u001b[38;5;241m=\u001b[39m p_k_new\u001b[38;5;241m.\u001b[39mlog_prob(torch\u001b[38;5;241m.\u001b[39mtensor(j))\n\u001b[1;32m    359\u001b[0m     \u001b[38;5;66;03m# Compute the log likelihood of F with k_new equaling j\u001b[39;00m\n\u001b[1;32m    360\u001b[0m     F_log_likelihood[j] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mF_loglik_given_k_new(cur_F_minus_ZA,Z,D,i,j)\n",
      "File \u001b[0;32m~/anaconda3/envs/py311/lib/python3.11/site-packages/torch/distributions/poisson.py:69\u001b[0m, in \u001b[0;36mPoisson.log_prob\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_args:\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_sample(value)\n\u001b[0;32m---> 69\u001b[0m rate, value \u001b[38;5;241m=\u001b[39m broadcast_all(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrate, value)\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m value\u001b[38;5;241m.\u001b[39mxlogy(rate) \u001b[38;5;241m-\u001b[39m rate \u001b[38;5;241m-\u001b[39m (value \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mlgamma()\n",
      "File \u001b[0;32m~/anaconda3/envs/py311/lib/python3.11/site-packages/torch/distributions/utils.py:22\u001b[0m, in \u001b[0;36mbroadcast_all\u001b[0;34m(*values)\u001b[0m\n\u001b[1;32m      9\u001b[0m euler_constant \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.57721566490153286060\u001b[39m  \u001b[38;5;66;03m# Euler Mascheroni Constant\u001b[39;00m\n\u001b[1;32m     11\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbroadcast_all\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogits_to_probs\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvec_to_tril_matrix\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     19\u001b[0m ]\n\u001b[0;32m---> 22\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbroadcast_all\u001b[39m(\u001b[38;5;241m*\u001b[39mvalues):\n\u001b[1;32m     23\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;124;03m    Given a list of values (possibly containing numbers), returns a list where each\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;124;03m    value is broadcasted based on the following rules:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;124;03m            a `torch.*Tensor` instance, or an instance implementing __torch_function__\u001b[39;00m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mall\u001b[39m(is_tensor_like(v) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(v, Number) \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m values):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "inf = UncollapsedGibbsIBP(alpha=0.05, K=1, max_K=6, sigma_a=0.2, sigma_n=0.0, epsilon=0.01, lambd=0.99, phi=0.25)\n",
    "\n",
    "As, Zs, Ys = inf.gibbs(F_dataset, X_dataset, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.88 -0.56]\n",
      " [-0.8   0.52]\n",
      " [ 0.84  0.48]\n",
      " [ 0.84 -0.48]]\n",
      "[[0. 1. 1. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 0. 1.]]\n",
      "[[1.  0.  0.  0. ]\n",
      " [0.  1.  0.  0. ]\n",
      " [0.  0.  0.  1. ]\n",
      " [0.  0.  1.  0. ]\n",
      " [0.  0.  0.  0. ]\n",
      " [0.  0.  0.  1. ]\n",
      " [0.  1.  0.  0. ]\n",
      " [0.  0.  1.  0. ]\n",
      " [0.  0.  0.  1. ]\n",
      " [0.  0.9 1.  0. ]\n",
      " [0.  0.  0.  1. ]\n",
      " [1.  0.  0.  0. ]\n",
      " [0.  1.  1.  0. ]\n",
      " [0.2 0.  0.  0.1]\n",
      " [0.  0.  1.  0. ]\n",
      " [0.  0.  0.  0. ]\n",
      " [0.  0.  1.  0. ]\n",
      " [1.  0.  0.  0. ]\n",
      " [0.  0.  1.  0. ]\n",
      " [1.  0.  0.1 0. ]\n",
      " [0.  0.9 1.  0. ]\n",
      " [0.  1.  0.  0. ]\n",
      " [0.  1.  1.  0. ]\n",
      " [0.1 0.  0.  0. ]\n",
      " [0.  1.  0.  0. ]\n",
      " [1.  0.  0.2 0. ]\n",
      " [0.  0.  0.  1. ]\n",
      " [0.  0.  1.  0. ]\n",
      " [1.  0.  0.1 0. ]\n",
      " [1.  0.  0.  0. ]\n",
      " [0.  0.  0.  0. ]\n",
      " [0.  1.  0.  0. ]\n",
      " [0.  0.  1.  0. ]\n",
      " [0.  0.  0.  0. ]\n",
      " [0.  0.  0.  1. ]\n",
      " [0.  0.  0.  0. ]\n",
      " [0.  1.  1.  0. ]\n",
      " [0.  0.  0.  1. ]\n",
      " [0.  1.  1.  0. ]\n",
      " [0.  1.  0.  0. ]\n",
      " [0.  1.  0.  0. ]\n",
      " [0.  1.  1.  0. ]\n",
      " [0.  0.9 0.  0. ]\n",
      " [0.2 0.  0.  0. ]\n",
      " [0.  1.  1.  0. ]\n",
      " [0.  0.  0.  1. ]\n",
      " [0.  1.  1.  0. ]\n",
      " [0.  1.  0.  0. ]\n",
      " [0.  1.  0.  0. ]\n",
      " [0.  1.  1.  0. ]\n",
      " [0.  0.  1.  0. ]\n",
      " [0.  0.  1.  0. ]\n",
      " [0.  0.  0.  1. ]\n",
      " [0.  1.  0.  0. ]\n",
      " [0.  1.  1.  0. ]\n",
      " [0.  1.  1.  0. ]\n",
      " [0.  0.  0.  0. ]\n",
      " [0.  0.  1.  0. ]\n",
      " [1.  0.  0.  0. ]\n",
      " [0.  0.  0.  1. ]\n",
      " [0.  0.  1.  0. ]\n",
      " [0.  1.  0.  0. ]\n",
      " [0.  0.  1.  0. ]\n",
      " [0.  0.  0.  1. ]\n",
      " [0.1 0.  0.  0. ]\n",
      " [0.  0.  1.  0. ]\n",
      " [0.1 0.  0.  0. ]\n",
      " [1.  0.  0.  0. ]\n",
      " [0.  0.  1.  0. ]\n",
      " [1.  0.  0.2 0. ]\n",
      " [0.  0.  0.  0.9]\n",
      " [0.  0.  0.  0. ]\n",
      " [0.  1.  1.  0. ]\n",
      " [0.  0.  0.  1. ]\n",
      " [0.  0.  0.  0. ]\n",
      " [0.  1.  1.  0. ]\n",
      " [1.  0.  0.  0. ]\n",
      " [1.  0.  0.  0. ]\n",
      " [1.  0.  0.1 0. ]\n",
      " [0.  1.  0.  0. ]\n",
      " [0.  1.  0.  0. ]\n",
      " [0.  0.  0.  0.9]\n",
      " [0.3 0.  0.  0. ]\n",
      " [1.  0.  0.  0. ]\n",
      " [0.  1.  0.  0. ]\n",
      " [0.  0.  1.  0. ]\n",
      " [0.  0.  1.  0. ]\n",
      " [1.  0.  0.1 0. ]\n",
      " [0.  0.  1.  0. ]\n",
      " [0.  0.  0.  0. ]\n",
      " [0.  1.  0.  0. ]\n",
      " [0.1 0.  0.  0. ]\n",
      " [0.  1.  0.  0. ]\n",
      " [0.  0.  0.  1. ]\n",
      " [0.  0.  1.  0. ]\n",
      " [1.  0.  0.2 0. ]\n",
      " [0.  1.  1.  0. ]\n",
      " [0.  0.  0.  0. ]\n",
      " [0.  1.  1.  0. ]\n",
      " [1.  0.  0.1 0. ]\n",
      " [0.  0.  0.  1. ]\n",
      " [0.  1.  0.  0. ]\n",
      " [0.  0.  0.  1. ]\n",
      " [0.  0.  0.9 0. ]\n",
      " [0.  0.  0.  0. ]\n",
      " [0.1 0.  0.  0. ]\n",
      " [0.  0.  1.  0. ]\n",
      " [0.  1.  1.  0. ]\n",
      " [0.1 0.  0.  0. ]\n",
      " [0.  1.  1.  0. ]\n",
      " [0.  0.  0.  0.9]\n",
      " [1.  0.  0.1 0. ]\n",
      " [1.  0.  0.1 0. ]\n",
      " [0.  1.  1.  0. ]\n",
      " [0.2 0.  0.  0. ]\n",
      " [0.  0.  0.  1. ]\n",
      " [0.  0.  1.  0. ]\n",
      " [0.  1.  0.  0. ]\n",
      " [1.  0.  0.1 0. ]\n",
      " [0.  0.  0.  1. ]\n",
      " [0.  1.  0.  0. ]\n",
      " [0.  1.  0.  0. ]\n",
      " [1.  0.  0.2 0. ]\n",
      " [0.  0.  0.  1. ]\n",
      " [0.  0.9 0.9 0. ]\n",
      " [0.  1.  1.  0. ]\n",
      " [0.  0.  1.  0. ]\n",
      " [0.1 0.  0.  0. ]\n",
      " [0.  1.  1.  0. ]\n",
      " [0.  0.  1.  0. ]\n",
      " [0.  1.  0.  0. ]\n",
      " [0.  0.  1.  0. ]\n",
      " [1.  0.  0.  0. ]\n",
      " [0.  0.  1.  0. ]\n",
      " [0.  0.  1.  0. ]\n",
      " [0.  1.  1.  0. ]\n",
      " [0.  0.  0.  0. ]\n",
      " [0.  0.  0.  1. ]\n",
      " [0.  1.  0.  0. ]\n",
      " [0.  0.  0.  0. ]\n",
      " [0.  0.  0.  1. ]\n",
      " [0.  0.  1.  0. ]\n",
      " [1.  0.  0.  0. ]\n",
      " [0.  0.  0.  1. ]\n",
      " [0.  1.  0.  0. ]\n",
      " [0.  0.  0.  1. ]\n",
      " [1.  0.  0.  0. ]\n",
      " [0.  1.  1.  0. ]\n",
      " [1.  0.  0.  0. ]\n",
      " [0.  1.  1.  0. ]\n",
      " [0.  1.  0.  0. ]\n",
      " [0.  1.  1.  0. ]\n",
      " [1.  0.  0.  0. ]\n",
      " [0.  1.  1.  0. ]\n",
      " [0.  0.  0.  0. ]\n",
      " [1.  0.  0.  0. ]\n",
      " [0.  1.  0.  0. ]\n",
      " [0.  1.  0.  0. ]\n",
      " [0.  0.  0.  1. ]\n",
      " [0.  1.  1.  0. ]\n",
      " [0.  1.  0.  0. ]\n",
      " [0.  0.  0.  1. ]\n",
      " [0.  0.  0.  0. ]\n",
      " [0.2 0.  0.  0. ]\n",
      " [0.  0.  1.  0. ]\n",
      " [1.  0.  0.  0. ]\n",
      " [0.  0.  0.  0. ]\n",
      " [0.  0.  0.  1. ]\n",
      " [0.  1.  1.  0. ]\n",
      " [1.  0.  0.1 0. ]\n",
      " [0.  1.  1.  0. ]\n",
      " [0.  1.  0.  0. ]\n",
      " [0.  0.  0.  0. ]\n",
      " [0.  0.  0.  1. ]\n",
      " [0.  1.  1.  0. ]\n",
      " [0.  0.  0.  1. ]\n",
      " [1.  0.  0.1 0. ]\n",
      " [0.  1.  0.  0. ]\n",
      " [0.  1.  0.  0. ]\n",
      " [0.  0.  0.  0. ]\n",
      " [0.  0.  1.  0. ]\n",
      " [0.  1.  1.  0. ]\n",
      " [0.  1.  0.  0. ]\n",
      " [1.  0.  0.  0. ]\n",
      " [0.  0.  1.  0. ]\n",
      " [1.  0.  0.3 0. ]\n",
      " [0.1 0.  0.  0. ]\n",
      " [0.  1.  1.  0. ]\n",
      " [0.  0.  0.  0. ]\n",
      " [0.  0.  0.  1. ]\n",
      " [0.  1.  1.  0. ]\n",
      " [0.  0.  0.  1. ]\n",
      " [1.  0.  0.1 0. ]\n",
      " [0.  0.  1.  0. ]\n",
      " [0.  1.  0.  0. ]\n",
      " [0.  0.  1.  0. ]\n",
      " [0.  0.  0.  1. ]\n",
      " [0.  0.  1.  0. ]\n",
      " [0.  0.  1.  0. ]\n",
      " [0.  0.  0.  1. ]]\n"
     ]
    }
   ],
   "source": [
    "A, Z, Y = extract_mean_from_samples(As, Zs, Ys, n=10)\n",
    "print(A*4)\n",
    "print(Y)\n",
    "print(Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_mean_from_samples(As, Zs, Ys, n=10):\n",
    "    A_mean = np.round(np.mean(np.array(As[-n:]),axis=0), 2)\n",
    "    Z_mean = np.round(np.mean(np.array(Zs[-n:]),axis=0), 2)\n",
    "    Y_mean = np.round(np.mean(np.array(Ys[-n:]),axis=0), 2)\n",
    "\n",
    "    return A_mean, Z_mean, Y_mean\n",
    "\n",
    "def compare_distance(reference_matrix, inferred_matrix):\n",
    "    \"\"\"\n",
    "    Compare the distance between rows of the reference and the true matrix.\n",
    "    use this to create a permutation matrix that reorders the inffered matrix to match the reference matrix,\n",
    "    and return the permutation matrix\n",
    "    \"\"\"\n",
    "    n, m = reference_matrix.shape\n",
    "    assert inferred_matrix.shape == (n, m)\n",
    "\n",
    "    # compute the distance matrix\n",
    "    distance_matrix = np.zeros((n, n))\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            distance_matrix[i, j] = np.linalg.norm(reference_matrix[i] - inferred_matrix[j])\n",
    "\n",
    "    # find the permutation that minimizes the distance\n",
    "    from scipy.optimize import linear_sum_assignment\n",
    "    row_ind, col_ind = linear_sum_assignment(distance_matrix)\n",
    "    \n",
    "    # create the permutation matrix that corresponds to this reordering\n",
    "    permutation_matrix = np.zeros((n, n))\n",
    "    for i in range(n):\n",
    "        permutation_matrix[i, col_ind[i]] = 1\n",
    "\n",
    "    return permutation_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True A:\n",
      "[[ 0.2  0.2]\n",
      " [-0.2  0.2]\n",
      " [ 0.  -0.2]]\n",
      "Inferred A:\n",
      "[[ 0.21  0.19]\n",
      " [-0.2   0.18]\n",
      " [-0.01 -0.17]]\n",
      "\n",
      "True Y:\n",
      "[[1. 0. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 0. 1.]]\n",
      "Inferred Y:\n",
      "[[1. 0. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 0. 1.]]\n",
      "\n",
      "True Z:\n",
      "[[1 0 0]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [1 1 0]\n",
      " [1 0 1]\n",
      " [0 1 1]\n",
      " [1 1 1]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [1 1 0]\n",
      " [1 0 1]\n",
      " [0 1 1]\n",
      " [1 1 1]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [1 1 0]\n",
      " [1 0 1]\n",
      " [0 1 1]\n",
      " [1 1 1]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [1 1 0]\n",
      " [1 0 1]\n",
      " [0 1 1]\n",
      " [1 1 1]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [1 1 0]\n",
      " [1 0 1]\n",
      " [0 1 1]\n",
      " [1 1 1]]\n",
      "Inferred Z:\n",
      "[[1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 1. 0.]\n",
      " [1. 0. 1.]\n",
      " [0. 1. 1.]\n",
      " [1. 1. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 1. 0.]\n",
      " [1. 0. 1.]\n",
      " [0. 1. 1.]\n",
      " [1. 1. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 1. 0.]\n",
      " [1. 0. 1.]\n",
      " [0. 1. 1.]\n",
      " [1. 1. 1.]\n",
      " [1. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 1. 0.]\n",
      " [1. 0. 1.]\n",
      " [0. 1. 1.]\n",
      " [1. 1. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 1. 0.]\n",
      " [1. 0. 1.]\n",
      " [0. 1. 1.]\n",
      " [1. 1. 1.]]\n"
     ]
    }
   ],
   "source": [
    "A, Z, Y = extract_mean_from_samples(As, Zs, Ys, n=10)\n",
    "\n",
    "reorder = compare_distance(true_A.numpy(), A)\n",
    "\n",
    "print(\"True A:\")\n",
    "print(true_A.numpy())\n",
    "print(\"Inferred A:\")\n",
    "print(np.round(reorder @ A,2))\n",
    "\n",
    "print(\"\\nTrue Y:\")\n",
    "print(true_Y.numpy())\n",
    "print(\"Inferred Y:\")\n",
    "print(np.round(reorder @ Y,2))\n",
    "\n",
    "print(\"\\nTrue Z:\")\n",
    "print(np.array(Z_latent))\n",
    "print(\"Inferred Z:\")\n",
    "print(np.round(Z @ reorder,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
